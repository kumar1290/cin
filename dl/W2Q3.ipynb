{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP with 1 hidden layer(s) and 64 neurons per layer...\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 7s 5ms/step - loss: 0.3541 - accuracy: 0.9031\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1693 - accuracy: 0.9515\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1238 - accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.0993 - accuracy: 0.9709\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.0828 - accuracy: 0.9755\n",
      "Test Accuracy: 0.9707000255584717\n",
      "\n",
      "Training MLP with 1 hidden layer(s) and 128 neurons per layer...\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3091 - accuracy: 0.9125\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1378 - accuracy: 0.9603\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.0954 - accuracy: 0.9724\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.0716 - accuracy: 0.9790\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.0563 - accuracy: 0.9833\n",
      "Test Accuracy: 0.9768999814987183\n",
      "\n",
      "Training MLP with 1 hidden layer(s) and 256 neurons per layer...\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.2611 - accuracy: 0.9255\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.1093 - accuracy: 0.9672\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.0739 - accuracy: 0.9780\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.0536 - accuracy: 0.9842\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.0394 - accuracy: 0.9879\n",
      "Test Accuracy: 0.9751999974250793\n",
      "\n",
      "Training MLP with 2 hidden layer(s) and 64 neurons per layer...\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 7s 6ms/step - loss: 0.3252 - accuracy: 0.9076\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.1456 - accuracy: 0.9568\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.1057 - accuracy: 0.9675\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.0828 - accuracy: 0.9751\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.0665 - accuracy: 0.9794\n",
      "Test Accuracy: 0.9732000231742859\n",
      "\n",
      "Training MLP with 2 hidden layer(s) and 128 neurons per layer...\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.2576 - accuracy: 0.9248\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.1074 - accuracy: 0.9676\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.0749 - accuracy: 0.9767\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0573 - accuracy: 0.9823\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0438 - accuracy: 0.9857\n",
      "Test Accuracy: 0.9735999703407288\n",
      "\n",
      "Training MLP with 2 hidden layer(s) and 256 neurons per layer...\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 5s 4ms/step - loss: 0.2174 - accuracy: 0.9352\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.0844 - accuracy: 0.9737\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0574 - accuracy: 0.9821\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0419 - accuracy: 0.9863\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 0.0327 - accuracy: 0.9895\n",
      "Test Accuracy: 0.9782000184059143\n",
      "\n",
      "Training MLP with 3 hidden layer(s) and 64 neurons per layer...\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run TensorDataset: Dst tensor is not initialized. [Op:TensorDataset]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m create_mlp(hidden_layers, neurons_per_layer)\n\u001b[0;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     30\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m _, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\manish kumar\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\manish kumar\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run TensorDataset: Dst tensor is not initialized. [Op:TensorDataset]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_flat = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "def create_mlp(hidden_layers, neurons_per_layer):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "hidden_layers_list = [1, 2, 3]\n",
    "neurons_per_layer_list = [64, 128, 256]\n",
    "for hidden_layers in hidden_layers_list:\n",
    "    for neurons_per_layer in neurons_per_layer_list:\n",
    "        print(f\"Training MLP with {hidden_layers} hidden layer(s) and {neurons_per_layer} neurons per layer...\")\n",
    "        model = create_mlp(hidden_layers, neurons_per_layer)\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
    "\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Test Accuracy: {accuracy}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
