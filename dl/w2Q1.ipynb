{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "594/594 [==============================] - 7s 7ms/step - loss: 0.3897 - accuracy: 0.8131 - val_loss: 0.3396 - val_accuracy: 0.8329\n",
      "Epoch 2/10\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.3360 - accuracy: 0.8420 - val_loss: 0.3277 - val_accuracy: 0.8471\n",
      "Epoch 3/10\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 0.3311 - accuracy: 0.8436 - val_loss: 0.3280 - val_accuracy: 0.8466\n",
      "Epoch 4/10\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 0.3280 - accuracy: 0.8451 - val_loss: 0.3221 - val_accuracy: 0.8480\n",
      "Epoch 5/10\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 0.3253 - accuracy: 0.8470 - val_loss: 0.3245 - val_accuracy: 0.8499\n",
      "Epoch 6/10\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 0.3231 - accuracy: 0.8466 - val_loss: 0.3220 - val_accuracy: 0.8513\n",
      "Epoch 7/10\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 0.3215 - accuracy: 0.8477 - val_loss: 0.3216 - val_accuracy: 0.8537\n",
      "Epoch 8/10\n",
      "594/594 [==============================] - 3s 6ms/step - loss: 0.3191 - accuracy: 0.8497 - val_loss: 0.3225 - val_accuracy: 0.8523\n",
      "Epoch 9/10\n",
      "594/594 [==============================] - 4s 6ms/step - loss: 0.3177 - accuracy: 0.8510 - val_loss: 0.3235 - val_accuracy: 0.8504\n",
      "Epoch 10/10\n",
      "594/594 [==============================] - 4s 6ms/step - loss: 0.3157 - accuracy: 0.8510 - val_loss: 0.3201 - val_accuracy: 0.8509\n",
      "283/283 [==============================] - 1s 4ms/step - loss: 0.3343 - accuracy: 0.8424\n",
      "Test Accuracy: 0.8424135446548462\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "data = pd.read_csv(\"adult.csv\")\n",
    "\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "cat_cols = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country', 'income']\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    data[col] = label_encoders[col].fit_transform(data[col])\n",
    "\n",
    "X = data.drop('income', axis=1)\n",
    "y = data['income']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manish kumar\\AppData\\Local\\Temp\\ipykernel_15728\\1180952168.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
      "C:\\Users\\manish kumar\\AppData\\Local\\Temp\\ipykernel_15728\\1180952168.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 27ms/step - loss: 0.6453 - accuracy: 0.7268 - val_loss: 0.5491 - val_accuracy: 0.8730\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.5555 - accuracy: 0.7821 - val_loss: 0.4537 - val_accuracy: 0.9048\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5023 - accuracy: 0.7964 - val_loss: 0.3880 - val_accuracy: 0.8889\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4749 - accuracy: 0.7964 - val_loss: 0.3487 - val_accuracy: 0.8889\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4590 - accuracy: 0.8000 - val_loss: 0.3329 - val_accuracy: 0.8889\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4480 - accuracy: 0.8054 - val_loss: 0.3254 - val_accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4384 - accuracy: 0.8107 - val_loss: 0.3177 - val_accuracy: 0.9048\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4337 - accuracy: 0.8089 - val_loss: 0.3133 - val_accuracy: 0.9206\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4284 - accuracy: 0.8161 - val_loss: 0.3134 - val_accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4224 - accuracy: 0.8304 - val_loss: 0.3133 - val_accuracy: 0.9048\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.8022\n",
      "Test Accuracy: 0.8022388219833374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "data = pd.read_csv(\"titanic/train.csv\")\n",
    "\n",
    "data = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "cat_cols = ['Sex', 'Embarked']\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    data[col] = label_encoders[col].fit_transform(data[col])\n",
    "\n",
    "X = data.drop('Survived', axis=1)\n",
    "y = data['Survived']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: -1.1321094297557328\n",
      "Epoch 10, Loss: -2.618234564731901\n",
      "Epoch 20, Loss: -4.018349076048764\n",
      "Epoch 30, Loss: -5.338511833381155\n",
      "Epoch 40, Loss: -5.851755325090107\n",
      "Epoch 50, Loss: -5.896252147861104\n",
      "Epoch 60, Loss: -5.910771747436191\n",
      "Epoch 70, Loss: -5.912749962593334\n",
      "Epoch 80, Loss: -5.9128095901664475\n",
      "Epoch 90, Loss: -5.912811064744773\n",
      "Test Accuracy: 0.6494252873563219\n",
      "Precision: 0.6494252873563219\n",
      "Recall: 1.0\n",
      "F1-score: 0.7874564459930313\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "data_url = \"indian_liver_patient.csv\"\n",
    "# data_url = \"../../indian_liver_patient.csv\"\n",
    "data = pd.read_csv(data_url)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data['Gender'] = data['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "X = data.drop('Dataset', axis=1)  \n",
    "y = data['Dataset']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define MLP class\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        # Initialize weights and biases for hidden layer\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        # Initialize weights and biases for output layer\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size)\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward pass through the network\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        # Compute binary cross-entropy loss\n",
    "        epsilon = 1e-10\n",
    "        loss = -np.mean(y_true * np.log(y_pred + epsilon) + (1 - y_true) * np.log(1 - y_pred + epsilon))\n",
    "        return loss\n",
    "\n",
    "    def backward(self, X, y_true):\n",
    "        # Backpropagation to update weights and biases\n",
    "        m = X.shape[0]\n",
    "        # Compute gradients for output layer\n",
    "        dz2 = self.a2 - y_true\n",
    "        dW2 = (1 / m) * np.dot(self.a1.T, dz2)\n",
    "        db2 = (1 / m) * np.sum(dz2, axis=0, keepdims=True)\n",
    "        # Compute gradients for hidden layer\n",
    "        dz1 = np.dot(dz2, self.W2.T) * self.a1 * (1 - self.a1)\n",
    "        dW1 = (1 / m) * np.dot(X.T, dz1)\n",
    "        db1 = (1 / m) * np.sum(dz1, axis=0, keepdims=True)\n",
    "        # Update weights and biases\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100):\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            y_pred = self.forward(X_train)\n",
    "            # Compute loss\n",
    "            loss = self.compute_loss(y_train, y_pred)\n",
    "            # Backward pass (backpropagation)\n",
    "            self.backward(X_train, y_train)\n",
    "            # Print loss for monitoring training progress\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions (binary classification)\n",
    "        y_pred = self.forward(X)\n",
    "        return (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Initialize and train MLP model\n",
    "input_size = X_train_scaled.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "mlp = MLP(input_size, hidden_size, output_size, learning_rate=0.1)\n",
    "mlp.train(X_train_scaled, y_train.values.reshape(-1, 1), epochs=100)\n",
    "\n",
    "# Evaluate model on test set\n",
    "y_pred_test = mlp.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
